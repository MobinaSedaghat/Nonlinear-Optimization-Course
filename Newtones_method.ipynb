{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLGNuUyFbstOu3uJFUKXEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MobinaSedaghat/Nonlinear-Optimization-Course/blob/main/Newtones_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXqf9FPO_3zA",
        "outputId": "b65376a5-c3d0-4ac2-ba88-e050eb53b2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hes = [[0.5 0. ]\n",
            " [0.  0.5]]\n",
            "grd = [2. 4.]\n",
            "multiply = [-1. -2.]\n",
            "\n",
            "point: [2.22044605e-16 4.44089210e-16], min: 2.465190328815662e-31\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numdifftools import Gradient\n",
        "from torch import tensor\n",
        "from torch.autograd.functional import hessian\n",
        "\n",
        "x = np.array([1., 2.])\n",
        "e = 0.00001\n",
        "\n",
        "def f(x):\n",
        "    # y = (2 * (x[0] ** 3)) + (3 * (x[1] ** 2)) + (3 * ((x[0] ** 2) * x[1])) - (24 * (x[1]))\n",
        "    y = x[0] ** 2 + x[1] ** 2\n",
        "    return y\n",
        "\n",
        "def norm(x):\n",
        "    y = 0\n",
        "    for i in range(len(x)):\n",
        "        y += x[i] ** 2\n",
        "\n",
        "    return y ** 0.5\n",
        "\n",
        "\n",
        "while norm(Gradient(f)(x)) > e:\n",
        "\n",
        "    inp = tensor(x)\n",
        "    hes = hessian(f, inp)\n",
        "\n",
        "    hes_inv = np.linalg.inv(hes)\n",
        "    hes_inv = np.array(hes_inv)\n",
        "    print(f'hes = {hes_inv}')\n",
        "\n",
        "    grd = Gradient(f)(x)\n",
        "    grd = np.array(grd)\n",
        "    print(f'grd = {grd}')\n",
        "\n",
        "    d = np.dot(hes_inv, grd)\n",
        "    d = np.multiply(d, -1)\n",
        "    x = np.add(x, d)\n",
        "    print(f'multiply = {d}')\n",
        "    print()\n",
        "\n",
        "print(f'point: {x}, min: {f(x)}')\n"
      ]
    }
  ]
}